import streamlit as st
from pipeline import generer_stories_depuis_besoin
from pipeline.interaction_engine import repondre_intelligemment

# Chargement du style iMessage
with open("styles.css") as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

st.set_page_config(page_title="Assistant IA â€” Analyse des besoins", layout="wide")
st.title("ğŸ“Š Assistant IA â€” Analyse des besoins et gÃ©nÃ©ration de livrables")

# Initialisation des Ã©tats
if "stories" not in st.session_state:
    st.session_state.stories = []
if "generated" not in st.session_state:
    st.session_state.generated = False
if "chat" not in st.session_state:
    st.session_state.chat = []

# Formulaire de gÃ©nÃ©ration
with st.form("besoin_form"):
    requete = st.text_area("ğŸ“ DÃ©cris les besoins mÃ©tier exprimÃ©s :", height=100)
    submitted = st.form_submit_button("ğŸš€ GÃ©nÃ©rer")

if submitted and requete:
    st.session_state.stories = generer_stories_depuis_besoin(requete)
    st.session_state.generated = True
    st.session_state.chat = []

# Affichage des livrables si gÃ©nÃ©rÃ©s
if st.session_state.generated:
    stories = st.session_state.stories
    rÃ´les = sorted(set(s["acteur"] for s in stories))
    tabs = st.tabs([f"ğŸ§‘â€ğŸ’¼ {r.capitalize()}" for r in rÃ´les] + ["ğŸ“˜ Exigences par rÃ´le", "ğŸ’¬ Assistant IA"])

    # Onglets par rÃ´le
    for i, rÃ´le in enumerate(rÃ´les):
        with tabs[i]:
            bloc = [s for s in stories if s["acteur"] == rÃ´le]
            for idx, s in enumerate(bloc, start=1):
                st.markdown(f"### ğŸ§© Story {idx}")
                st.markdown(f"**User Story**\n\n{s['story']}")
                st.markdown("**ğŸ“˜ Exigences BABOK**")
                for typ, babok, texte in s["exigences"]:
                    st.markdown(f"- **{typ}** : {texte}  \nâ†ª *({babok})*")
                st.markdown("**âœ… CritÃ¨res dâ€™acceptation**")
                for c in s["critÃ¨res"]:
                    st.markdown(f"- {c}")
                st.markdown("**ğŸ§ª Tests fonctionnels**")
                for t in s["tests"]:
                    st.markdown(f"- {t}")
                st.markdown("**ğŸ’¡ Suggestions IA**")
                for sug in s["suggestions"]:
                    st.markdown(f"- {sug}")
                st.markdown(f"**ğŸ”’ Validation mÃ©tier**\n\n{s['validation']}")

    # Exigences par rÃ´le
    with tabs[-2]:
        sous_tabs = st.tabs([f"ğŸ§‘â€ğŸ’¼ {r.capitalize()}" for r in rÃ´les])
        for i, rÃ´le in enumerate(rÃ´les):
            with sous_tabs[i]:
                bloc = [s for s in stories if s["acteur"] == rÃ´le]
                for idx, s in enumerate(bloc, start=1):
                    st.markdown(f"### ğŸ§© Story {idx}")
                    st.markdown(f"**User Story**\n\n{s['story']}")
                    st.markdown("**ğŸ“˜ Exigences associÃ©es**")
                    for typ, babok, texte in s["exigences"]:
                        st.markdown(f"- **{typ}** : {texte}  \nâ†ª *({babok})*")

    # Assistant IA style iMessage
    with tabs[-1]:
        st.header("ğŸ’¬ Assistant IA â€” Style iMessage")

        st.markdown('<div class="chat-container">', unsafe_allow_html=True)

        for msg in st.session_state.chat:
            role_class = "user-bubble" if msg["role"] == "user" else "assistant-bubble"
            st.markdown(f'<div class="{role_class}">{msg["content"]}</div>', unsafe_allow_html=True)

        st.markdown('</div>', unsafe_allow_html=True)

        user_input = st.chat_input("ğŸ’¬ Envoie un message comme dans iMessageâ€¦")
        if user_input:
            st.session_state.chat.append({"role": "user", "content": user_input})
            st.markdown('<div class="typing-indicator">Lâ€™IA est en train dâ€™Ã©crireâ€¦</div>', unsafe_allow_html=True)
            response = repondre_intelligemment(user_input, st.session_state.stories)
            st.session_state.chat.append({"role": "assistant", "content": response})
